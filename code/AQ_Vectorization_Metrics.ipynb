{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wja8QIp_sl6R",
        "outputId": "94d22526-3e36-474b-dd1b-f9050402eba8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import entropy\n",
        "import pygeohash as pgh\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drWP8E8as7iy"
      },
      "outputs": [],
      "source": [
        "samples_path = r\".\\generated_samples_0.6\"\n",
        "refrence_path = r\".\\AQ_NYC_orignal_1.tiff\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcGWMk7ptSUg"
      },
      "outputs": [],
      "source": [
        "def encode_geohash(latitude, longitude, key=key1):\n",
        "    return pgh.encode(latitude, longitude, key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B6b8iZFtTSQ"
      },
      "outputs": [],
      "source": [
        "def DataframeGenerator(image1):\n",
        "  band1_values = image1.GetRasterBand(1).ReadAsArray()\n",
        "  band2_values = image1.GetRasterBand(2).ReadAsArray()\n",
        "  band3_values = image1.GetRasterBand(3).ReadAsArray()\n",
        "\n",
        "  rows, cols = band1_values.shape\n",
        "\n",
        "  latitude = []\n",
        "  longitude = []\n",
        "  pm25_values = []\n",
        "\n",
        "  for row in range(rows):\n",
        "      for col in range(cols):\n",
        "          latitude.append(band2_values[row, col])\n",
        "          longitude.append(band3_values[row, col])\n",
        "          pm25_values.append(band1_values[row, col])\n",
        "\n",
        "  df = pd.DataFrame({'latitude': latitude, 'longitude': longitude, 'pm2.5 values': pm25_values})\n",
        "\n",
        "  df_filtered = df[(df != 0).all(axis=1)]\n",
        "\n",
        "  df_filtered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  df_filtered['Geohash'] = df_filtered.apply(lambda row: encode_geohash(row['latitude'], row['longitude']), axis=1)\n",
        "\n",
        "  df_filtered = df_filtered.drop_duplicates(subset='Geohash')\n",
        "  df_filtered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  return df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7xHdVpYtY4P"
      },
      "outputs": [],
      "source": [
        "def Geohash_Mismatch_Fixer(df1, df2):\n",
        "  geohashes_df1 = set(df1['Geohash'])\n",
        "  geohashes_df2 = set(df2['Geohash'])\n",
        "\n",
        "  missing_in_df1 = geohashes_df2 - geohashes_df1\n",
        "  missing_in_df2 = geohashes_df1 - geohashes_df2\n",
        "\n",
        "  missing_df1 = pd.DataFrame({'Geohash': list(missing_in_df1), 'pm2.5 values': [0] * len(missing_in_df1), 'latitude': [0] * len(missing_in_df1), 'longitude': [0] * len(missing_in_df1)})\n",
        "  df1 = pd.concat([df1, missing_df1], ignore_index=True)\n",
        "\n",
        "  missing_df2 = pd.DataFrame({'Geohash': list(missing_in_df2), 'pm2.5 values': [0] * len(missing_in_df2), 'latitude': [0] * len(missing_in_df2), 'longitude': [0] * len(missing_in_df2)})\n",
        "  df2 = pd.concat([df2, missing_df2], ignore_index=True)\n",
        "\n",
        "  return df1, df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqyF4qwTtd8X"
      },
      "outputs": [],
      "source": [
        "def RMSE_Calculator(df1, df2):\n",
        "  merged_df = pd.merge(df1, df2, on='Geohash', suffixes=('_1', '_2'))\n",
        "\n",
        "  merged_df['squared_diff'] = (merged_df['pm2.5 values_1'] - merged_df['pm2.5 values_2'])**2\n",
        "\n",
        "  mse = merged_df['squared_diff'].mean()\n",
        "\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def MAPE_Calculator(df1, df2):\n",
        "    merged_df = pd.merge(df1, df2, on='Geohash', suffixes=('_1', '_2'))\n",
        "    merged_df['absolute_percentage_diff'] = np.abs(merged_df['pm2.5 values_1'] - merged_df['pm2.5 values_2']) / merged_df['pm2.5 values_2']\n",
        "    mape = merged_df['absolute_percentage_diff'].mean() * 100\n",
        "    return mape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Jensen_Shannon_Divergence_Calculator(df1, df2):\n",
        "    merged_df = pd.merge(df1, df2, on='Geohash', suffixes=('_1', '_2'))\n",
        "    p = (merged_df['pm2.5 values_1'] + merged_df['pm2.5 values_2']) / 2\n",
        "    jsd = (entropy(merged_df['pm2.5 values_1'], p) + entropy(merged_df['pm2.5 values_2'], p)) / 2\n",
        "    return jsd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Kullback_Leibler_Divergence_Calculator(df1, df2):\n",
        "    merged_df = pd.merge(df1, df2, on='Geohash', suffixes=('_1', '_2'))\n",
        "    kl_div = entropy(merged_df['pm2.5 values_1'], merged_df['pm2.5 values_2'])\n",
        "    return kl_div"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "refrence_image = gdal.Open(refrence_path)\n",
        "\n",
        "image1_pm25_values_layer4 = refrence_image.GetRasterBand(4).ReadAsArray()\n",
        "non_zero_values1 = image1_pm25_values_layer4[image1_pm25_values_layer4 != 0]\n",
        "key1 = min(np.unique(non_zero_values1))\n",
        "\n",
        "refrence_df = DataframeGenerator(refrence_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RMSE_df = pd.DataFrame(columns=['sample_name', 'RMSE'])\n",
        "\n",
        "start_time = time.time()\n",
        "for sample_name in os.listdir(samples_path):\n",
        "    sample_path = os.path.join(samples_path, sample_name)\n",
        "    sample_image = gdal.Open(sample_path)\n",
        "\n",
        "    sample_df = DataframeGenerator(sample_image)\n",
        "    \n",
        "    sample_df, refrence_df = Geohash_Mismatch_Fixer(sample_df, refrence_df)\n",
        "    \n",
        "    RMSE_Value = RMSE_Calculator(sample_df, refrence_df)\n",
        "    \n",
        "    temp_df = pd.DataFrame({'sample_name': [sample_name], 'RMSE': [RMSE_Value]})\n",
        "    RMSE_df = pd.concat([RMSE_df, temp_df], ignore_index=True)\n",
        "    \n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "RMSE_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAPE_df = pd.DataFrame(columns=['sample_name', 'MAPE'])\n",
        "\n",
        "start_time = time.time()\n",
        "for sample_name in os.listdir(samples_path):\n",
        "    sample_path = os.path.join(samples_path, sample_name)\n",
        "    sample_image = gdal.Open(sample_path)\n",
        "\n",
        "    sample_df = DataframeGenerator(sample_image)\n",
        "    \n",
        "    sample_df, refrence_df = Geohash_Mismatch_Fixer(sample_df, refrence_df)\n",
        "    \n",
        "    MAPE_Value = MAPE_Calculator(sample_df, refrence_df)\n",
        "    \n",
        "    temp_df = pd.DataFrame({'sample_name': [sample_name], 'MAPE': [MAPE_Value]})\n",
        "    MAPE_df = pd.concat([MAPE_df, temp_df], ignore_index=True)\n",
        "    \n",
        "end_time = time.time()\n",
        "MAPE_execution_time = end_time - start_time\n",
        "MAPE_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Jensen_Shannon_Divergence_df = pd.DataFrame(columns=['sample_name', 'Jensen_Shannon_Divergence'])\n",
        "\n",
        "start_time = time.time()\n",
        "for sample_name in os.listdir(samples_path):\n",
        "    sample_path = os.path.join(samples_path, sample_name)\n",
        "    sample_image = gdal.Open(sample_path)\n",
        "\n",
        "    sample_df = DataframeGenerator(sample_image)\n",
        "    \n",
        "    sample_df, refrence_df = Geohash_Mismatch_Fixer(sample_df, refrence_df)\n",
        "    \n",
        "    Jensen_Shannon_Divergence_Value = Jensen_Shannon_Divergence_Calculator(sample_df, refrence_df)\n",
        "    \n",
        "    temp_df = pd.DataFrame({'sample_name': [sample_name], 'Jensen_Shannon_Divergence': [Jensen_Shannon_Divergence_Value]})\n",
        "    Jensen_Shannon_Divergence_df = pd.concat([Jensen_Shannon_Divergence_df, temp_df], ignore_index=True)\n",
        "    \n",
        "end_time = time.time()\n",
        "Jensen_Shannon_Divergence_execution_time = end_time - start_time\n",
        "Jensen_Shannon_Divergence_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Kullback_Leibler_Divergence_df = pd.DataFrame(columns=['sample_name', 'Kullback_Leibler_Divergence'])\n",
        "\n",
        "start_time = time.time()\n",
        "for sample_name in os.listdir(samples_path):\n",
        "    sample_path = os.path.join(samples_path, sample_name)\n",
        "    sample_image = gdal.Open(sample_path)\n",
        "\n",
        "    sample_df = DataframeGenerator(sample_image)\n",
        "    \n",
        "    sample_df, refrence_df = Geohash_Mismatch_Fixer(sample_df, refrence_df)\n",
        "    \n",
        "    Kullback_Leibler_Divergence_Value = Kullback_Leibler_Divergence_Calculator(sample_df, refrence_df)\n",
        "    \n",
        "    temp_df = pd.DataFrame({'sample_name': [sample_name], 'Kullback_Leibler_Divergence': [Kullback_Leibler_Divergence_Value]})\n",
        "    Kullback_Leibler_Divergence_df = pd.concat([Kullback_Leibler_Divergence_df, temp_df], ignore_index=True)\n",
        "    \n",
        "end_time = time.time()\n",
        "Kullback_Leibler_Divergence_Value_execution_time = end_time - start_time\n",
        "Kullback_Leibler_Divergence_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_RMSE = RMSE_df.loc[RMSE_df['RMSE'].idxmin()]\n",
        "min_MAPE = MAPE_df.loc[MAPE_df['MAPE'].idxmin()]\n",
        "min_Jensen_Shannon_Divergence = Jensen_Shannon_Divergence_df.loc[Jensen_Shannon_Divergence_df['Jensen_Shannon_Divergence'].idxmin()]\n",
        "min_Kullback_Leibler_Divergence = Kullback_Leibler_Divergence_df.loc[Kullback_Leibler_Divergence_df['Kullback_Leibler_Divergence'].idxmin()]\n",
        "\n",
        "print(min_RMSE)\n",
        "print(min_MAPE)\n",
        "print(min_Jensen_Shannon_Divergence)\n",
        "print(min_Kullback_Leibler_Divergence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'comparing_analysis_0.6.csv'\n",
        "data = {\n",
        "    'Metric': ['RMSE', 'MAPE', 'Jensen_Shannon_Divergence', 'Kullback_Leibler_Divergence'],\n",
        "    'Value': [min_RMSE['RMSE'], min_MAPE['MAPE'], min_Jensen_Shannon_Divergence['Jensen_Shannon_Divergence'], min_Kullback_Leibler_Divergence['Kullback_Leibler_Divergence']],\n",
        "    'sample_number': [min_RMSE['sample_name'], min_MAPE['sample_name'], min_Jensen_Shannon_Divergence['sample_name'], min_Kullback_Leibler_Divergence['sample_name']],\n",
        "    'comparing_time_in_second': [execution_time, MAPE_execution_time, Jensen_Shannon_Divergence_execution_time, Kullback_Leibler_Divergence_Value_execution_time]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.to_csv(file_path , index=False)\n",
        "\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
